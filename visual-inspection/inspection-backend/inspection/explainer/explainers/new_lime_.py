"""XAI Demonstrator LIME explainer"""
from typing import Dict
import numpy as np
import tensorflow as tf
from skimage.color import rgb2gray
from skimage.filters import sobel
from skimage.segmentation import felzenszwalb, slic, quickshift, watershed
from sklearn.linear_model import Lasso, BayesianRidge, LinearRegression


def explain_image(img: np.ndarray, seg_method: str, seg_settings: Dict, num_of_samples: int, samples_p: float,
                  model_: tf.keras.models.Model, threshold: float, volume: int, colour: str) -> np.ndarray:
    segment_mask = create_segments(img=img, seg_method=seg_method, settings=seg_settings)
    samples_theo = generate_samples(segment_mask=segment_mask, num_of_samples=num_of_samples, p=samples_p)
    samples_imgs = generate_images(image=img, segment_mask=segment_mask, samples=samples_theo)
    samples_imgs_predictions = predict_images(images = samples_imgs, model_=model_)
    weighted_segments = weigh_segments(samples=samples_theo, predictions=samples_imgs_predictions)
    visual_explanation = generate_visual_explanation(weighted_segments=weighted_segments, segment_mask=segment_mask,
                                                    image=img, threshold=threshold, volume=volume, colour=colour)

    return visual_explanation


def create_segments(img: np.ndarray, seg_method: str, settings: Dict) -> np.ndarray:
    """
    create segments out of a loaded picture using different methods and settings

    Parameters
    ----------
    img
    seg_method
    settings

    Returns
    -------

    """
    # TODO: Allow for changes in settings
    # TODO: Reduce to practically useful segmentation variants
    if seg_method == "felzenszwalb":
        return felzenszwalb(image=img, scale=250, sigma=0.6, min_size=45)

    if seg_method == "slic":
        return slic(image=img, n_segments=250, compactness=2, convert2lab=True, sigma=1, start_label=1)

    if seg_method == "quickshift":
        return quickshift(image=img, kernel_size=5, max_dist=6, ratio=0.7)  # mb sigma = 6

    if seg_method == "watershed":
        gradient = sobel(rgb2gray(img))
        return watershed(image=gradient, markers=250, compactness=0.001)

    else:
        raise ValueError("{} is not a valid segmentation method".format(seg_method))


def generate_samples(segment_mask: np.ndarray, num_of_samples: int, p: float) -> np.ndarray:
    """
    determine which segments are displayed for each sample

    Parameters
    ----------
    segment_mask : np.ndarray
        The mask generated by `create_segments()`: An array of the same dimension as the image
    num_of_samples : int
        The number of samples to generate
    p : float
        The probability for each segment to be replaced
    Returns
    -------
    samples : np.ndarray
        A two-dimensional array of dimension (num_of_samples, number_of_segments)
    """
    num_of_segments = np.max(segment_mask) + 1
    # TODO: Do not loop, but generate entire array in one step
    org_img_sample = np.ones((1, num_of_segments))
    # append a full 1's sample to generate and predict the original image later on to avoid variance
    return np.append(np.array([np.random.binomial(n=1, p=p, size=num_of_segments) for i in range(num_of_samples)]),
                     org_img_sample, axis=0)


def generate_images(image: np.ndarray, segment_mask: np.ndarray, samples: np.ndarray) -> np.ndarray:
    """Generating example images with each excluded segments in black


    Parameters
    ----------
    image
    segment_mask
    samples

    Returns
    -------

    """
    images = np.zeros((samples.shape[0],) + image.shape)
    segment_mask = segment_mask.reshape(image.shape[:2] + (1,))
    segment_ids = np.unique(segment_mask)

    # TODO: Do not loop (twice)
    for i, sample in enumerate(samples):
        mask = np.zeros(image.shape)
        for s_id in segment_ids:
            if sample[s_id]:
                mask += segment_mask == s_id
        images[i] = mask * image

    return images


def predict_images(images: np.ndarray, model_: tf.keras.models.Model) -> np.ndarray:
    """

    Parameters
    ----------
    images : np.ndarray
        Images as an array of dimension (num_of_samples, IMG_SIZE, IMG_SIZE, 3)
    model_ : tf.keras.models.Model
        A tf.keras model that takes an input of size (IMG_SIZE, IMG_SIZE, 3)

    Returns
    -------
    An array of size (num_of_samples, output_dimension)

    """
    return model_.predict(images)


def weigh_segments(samples: np.ndarray, predictions: np.ndarray) -> np.ndarray:
    """Generating list of coefficients to weigh segments


    Parameters
    ----------
    samples
    predictions

    Returns
    -------
    Array of size (num_of_segments)
    """
    # decide which linear regression model to use
    models = [BayesianRidge(), Lasso(), LinearRegression()]
    model = models[0]
    # get the  prediction-Id/column from the original image
    prev_label_id = np.bincount(np.argmax(predictions, axis=1)).argmax()

    # isolate the column from predictions
    p_column = predictions[:-1, prev_label_id]

    model.fit(samples[:-1], p_column)
    return model.coef_


def generate_visual_explanation(weighted_segments: np.ndarray, segment_mask: np.ndarray, image: np.ndarray,
                                threshold: float, volume: int, colour: str) -> np.ndarray:
    """Generating image with visual explanation


    Parameters

    ----------
    weighted_segment
    segment_mask
    image
    threshold
    volume
    colour

    Returns
    -------

    """
    # set explanation colour
    colours = {"green": [119, 184, 53], "blue": [38, 55, 173], "red": [173, 38, 38], "white": [255, 255, 255],
               "black": [0, 0, 0]}
    colour = colour.lower()
    if colour not in colours.keys():
        colour = "green"

    # handle outliers
    weighted_segments = np.where(weighted_segments > 1.0, 1, weighted_segments)
    weighted_segments = np.where(weighted_segments < -1.0, -1, weighted_segments)
    # normalize coefficients: coefficient_i âˆˆ [0.0, 1.0]
    n_weighted_segments = (weighted_segments - weighted_segments.min()) / (
            weighted_segments.max() - weighted_segments.min())

    # check if volume is bigger than the amount of segments
    max_volume = len(np.unique(segment_mask))
    if volume > max_volume:
        volume = max_volume

    # differentiate n_weighted_segments with respect to threshold and volume
    # values less than max(limit, threshold) are set to 0
    limit = np.sort(np.unique(n_weighted_segments))[-volume]
    n_d_weighted_segments = np.where(n_weighted_segments >= max(limit, threshold), n_weighted_segments,
                                     0)
    # manipulate the original image (quick and dirty)
    c = np.array(colours[colour])
    indices = np.argwhere(n_d_weighted_segments != 0)
    for i, row in enumerate(segment_mask):
        for j, el in enumerate(row):
            if el in indices:
                image[i, j] = round(n_d_weighted_segments[el], 1) * c / 255

    return image
